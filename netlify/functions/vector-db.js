/**
 * Netlify Function: ë©”ëª¨ë¦¬ ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ (ê¼¬ë§¨í‹€ SQLite ëŒ€ì²´)
 * SQLite ëŒ€ì‹  ë©”ëª¨ë¦¬ ìºì‹œë¡œ ë²¡í„° ê´€ë¦¬
 */

// ë©”ëª¨ë¦¬ ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ (ê¼¬ë§¨í‹€ì˜ SQLite ëŒ€ì²´)
const VECTOR_CACHE = new Map();
let isInitialized = false;

// ì‹¤ì œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ê¼¬ë§¨í‹€ì˜ cosine_similarity í•¨ìˆ˜)
function calculateCosineSimilarity(vec1, vec2) {
  if (!vec1 || !vec2 || vec1.length !== vec2.length) {
    return 0;
  }
  
  // vec1.dot(vec2) / (norm(vec1) * norm(vec2))
  let dotProduct = 0;
  let norm1 = 0;
  let norm2 = 0;
  
  for (let i = 0; i < vec1.length; i++) {
    dotProduct += vec1[i] * vec2[i];
    norm1 += vec1[i] * vec1[i];
    norm2 += vec2[i] * vec2[i];
  }
  
  norm1 = Math.sqrt(norm1);
  norm2 = Math.sqrt(norm2);
  
  if (norm1 === 0 || norm2 === 0) return 0;
  
  return dotProduct / (norm1 * norm2);
}

// ì˜ë¯¸ì  ë²¡í„° ìƒì„± (FastText ìŠ¤íƒ€ì¼ ì‹œë®¬ë ˆì´ì…˜)
function generateSemanticVector(concept, dimensions = 300, basePattern = []) {
  const vector = new Array(dimensions);
  
  // ê¸°ë³¸ íŒ¨í„´ì´ ì£¼ì–´ì§„ ê²½ìš° í™•ì¥
  for (let i = 0; i < dimensions; i++) {
    if (i < basePattern.length) {
      // ê¸°ë³¸ íŒ¨í„´ + ë…¸ì´ì¦ˆ
      vector[i] = basePattern[i] + (Math.random() - 0.5) * 0.1;
    } else {
      // ëœë¤í•˜ì§€ë§Œ ì¼ê´€ì„± ìˆëŠ” ê°’ (-0.5 ~ 0.5 ë²”ìœ„)
      const seed = concept.charCodeAt(i % concept.length) + i;
      vector[i] = (Math.sin(seed) + Math.cos(seed * 1.618)) * 0.25;
    }
  }
  
  return vector;
}

// NumPy ìŠ¤íƒ€ì¼ ìµœê·¼ì ‘ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ (ê¼¬ë§¨í‹€ì˜ most_similar í•¨ìˆ˜)
function mostSimilar(allVectors, targetVector, k = 1000) {
  const similarities = [];
  
  // ëª¨ë“  ë²¡í„°ì™€ì˜ ìœ ì‚¬ë„ ê³„ì‚°
  for (const [word, vector] of allVectors) {
    const similarity = calculateCosineSimilarity(targetVector, vector);
    similarities.push({ word, similarity });
  }
  
  // ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (numpyì˜ argsort[::-1]ê³¼ ë™ì¼)
  similarities.sort((a, b) => b.similarity - a.similarity);
  
  // ìƒìœ„ kê°œë§Œ ë°˜í™˜ (numpyì˜ argpartitionê³¼ ìœ ì‚¬)
  const topK = similarities.slice(0, Math.min(k, similarities.length));
  
  return {
    words: topK.map(item => item.word),
    similarities: topK.map(item => item.similarity),
    indices: topK.map((item, index) => index) // ì •ë ¬ëœ ì¸ë±ìŠ¤
  };
}

// ê¼¬ë§¨í‹€ì˜ dump_nearest í•¨ìˆ˜ êµ¬í˜„ (process_similar.py ì°¸ê³ )
function dumpNearest(targetWord, allVectors, k = 1000) {
  const targetVector = VECTOR_CACHE.get(targetWord);
  if (!targetVector) {
    throw new Error(`Target word "${targetWord}" not found in vector cache`);
  }
  
  // ìê¸° ìì‹ ì„ ì œì™¸í•œ ë²¡í„°ë“¤ë¡œ ìµœê·¼ì ‘ ê²€ìƒ‰
  const otherVectors = Array.from(VECTOR_CACHE.entries())
    .filter(([word, _]) => word !== targetWord);
  
  const nearestResult = mostSimilar(otherVectors, targetVector, k);
  
  // ê¼¬ë§¨í‹€ê³¼ ë™ì¼í•œ í˜•íƒœë¡œ ê²°ê³¼ êµ¬ì„±: closeness[word] = (rank, similarity)
  const closeness = {};
  
  nearestResult.words.forEach((word, index) => {
    closeness[word] = [index + 1, nearestResult.similarities[index]]; // (ìˆœìœ„, ìœ ì‚¬ë„)
  });
  
  // ì •ë‹µ ë‹¨ì–´ ì¶”ê°€ (ê¼¬ë§¨í‹€: closeness[word] = ("ì •ë‹µ!", 1))
  closeness[targetWord] = ["ì •ë‹µ!", 1.0];
  
  return closeness;
}

// ê¼¬ë§¨í‹€ì˜ get_similarity í•¨ìˆ˜ êµ¬í˜„ (semantle.py ì°¸ê³ )
function calculateSimilarityStats(targetWord) {
  try {
    const closeness = dumpNearest(targetWord, VECTOR_CACHE);
    
    // ëª¨ë“  ìœ ì‚¬ë„ ê°’ ì¶”ì¶œí•˜ì—¬ ì •ë ¬ (ê¼¬ë§¨í‹€: sorted([v[1] for v in app.nearests[day].values()]))
    const allSimilarities = Object.values(closeness)
      .map(([rank, similarity]) => similarity)
      .filter(sim => sim !== 1.0) // ì •ë‹µ ë‹¨ì–´(1.0) ì œì™¸
      .sort((a, b) => a - b); // ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
    
    // ê¼¬ë§¨í‹€ê³¼ ë™ì¼í•œ í†µê³„ ìƒì„±
    const stats = {
      top: allSimilarities[allSimilarities.length - 2] || 0.95,    // nearest_dists[-2]
      top10: allSimilarities[allSimilarities.length - 11] || 0.75, // nearest_dists[-11]  
      rest: allSimilarities[0] || 0.05,                            // nearest_dists[0]
      totalWords: allSimilarities.length + 1, // +1 for target word
      targetWord: targetWord
    };
    
    console.log(`ğŸ“Š Similarity stats for "${targetWord}": top=${(stats.top*100).toFixed(1)}%, top10=${(stats.top10*100).toFixed(1)}%, rest=${(stats.rest*100).toFixed(1)}%`);
    
    return stats;
    
  } catch (error) {
    console.error(`Failed to calculate stats for "${targetWord}":`, error.message);
    return null;
  }
}

// ë²¡í„° ìºì‹œ ì´ˆê¸°í™” (ê¼¬ë§¨í‹€ ì£¼ìš” ë‹¨ì–´ë“¤)
function initializeVectorCache() {
  if (isInitialized) return;
  
  console.log('ğŸŒ± Initializing vector cache with key Korean words...');
  
  // ì‹¤ì œ FastText ìŠ¤íƒ€ì¼ ë²¡í„° ìƒì„± (300ì°¨ì› ì‹œë®¬ë ˆì´ì…˜)
  const keyWordVectors = {
    // ì‹œê°„ í´ëŸ¬ìŠ¤í„° (ë†’ì€ ìœ ì‚¬ë„)
    "ì‹œê°„": generateSemanticVector("time", 300, [0.1, 0.3, -0.2, 0.4, 0.1]),
    "ì‹œê³„": generateSemanticVector("clock", 300, [0.15, 0.35, -0.15, 0.45, 0.12]), // ì‹œê°„ê³¼ ìœ ì‚¬
    "ë¶„": generateSemanticVector("minute", 300, [0.12, 0.28, -0.18, 0.38, 0.08]),
    "ì´ˆ": generateSemanticVector("second", 300, [0.08, 0.25, -0.22, 0.35, 0.05]),
    "ì‹œê°": generateSemanticVector("time_point", 300, [0.13, 0.32, -0.19, 0.42, 0.11]),
    
    // êµìœ¡ í´ëŸ¬ìŠ¤í„° (ë†’ì€ ìœ ì‚¬ë„)
    "í•™êµ": generateSemanticVector("school", 300, [-0.1, 0.4, 0.2, -0.2, 0.3]),
    "êµìœ¡": generateSemanticVector("education", 300, [-0.05, 0.45, 0.25, -0.15, 0.35]), // í•™êµì™€ ìœ ì‚¬
    "í•™ìƒ": generateSemanticVector("student", 300, [-0.08, 0.38, 0.18, -0.18, 0.28]),
    "ì„ ìƒë‹˜": generateSemanticVector("teacher", 300, [-0.12, 0.42, 0.22, -0.22, 0.32]),
    "ê³µë¶€": generateSemanticVector("study", 300, [-0.09, 0.41, 0.19, -0.19, 0.29]),
    
    // ê²°ê³¼ í´ëŸ¬ìŠ¤í„° (ì¤‘ê°„ ìœ ì‚¬ë„)
    "ê²°ê³¼": generateSemanticVector("result", 300, [0.3, -0.1, 0.4, 0.2, -0.3]),
    "ì„±ê³¼": generateSemanticVector("achievement", 300, [0.35, -0.05, 0.45, 0.25, -0.25]), // ê²°ê³¼ì™€ ìœ ì‚¬
    "ë§ˆì§€ë§‰": generateSemanticVector("final", 300, [0.28, -0.08, 0.38, 0.18, -0.28]),
    "ì™„ë£Œ": generateSemanticVector("complete", 300, [0.32, -0.06, 0.42, 0.22, -0.26]),
    
    // ê¸°íƒ€ ì¤‘ìš” ë‹¨ì–´ë“¤
    "ì‚¬ëŒ": generateSemanticVector("person", 300, [0.2, 0.1, -0.3, 0.1, 0.4]),
    "ì§‘": generateSemanticVector("house", 300, [0.1, -0.2, 0.3, -0.1, 0.2]),
    "ìŒì‹": generateSemanticVector("food", 300, [-0.2, 0.3, 0.1, 0.4, -0.1]),
    "ê±´ê°•": generateSemanticVector("health", 300, [0.4, 0.2, -0.1, 0.3, 0.1]),
  };
  
  // ëª¨ë“  ë²¡í„°ë¥¼ ìºì‹œì— ì €ì¥
  for (const [word, vector] of Object.entries(keyWordVectors)) {
    VECTOR_CACHE.set(word, vector);
  }
  
  isInitialized = true;
  console.log(`âœ… Initialized vector cache with ${VECTOR_CACHE.size} key word vectors`);
}

// Netlify Function í•¸ë“¤ëŸ¬
exports.handler = async (event, context) => {
  const headers = {
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Headers': 'Content-Type',
    'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
    'Content-Type': 'application/json'
  };
  
  // CORS preflight
  if (event.httpMethod === 'OPTIONS') {
    return { statusCode: 200, headers };
  }
  
  try {
    const { action, word1, word2 } = JSON.parse(event.body || '{}');
    
    // ë²¡í„° ìºì‹œ ì´ˆê¸°í™”
    initializeVectorCache();
    
    switch (action) {
      case 'similarity':
        // ì‹¤ì œ ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
        if (!word1 || !word2) {
          return {
            statusCode: 400,
            headers,
            body: JSON.stringify({ error: 'Missing word1 or word2' })
          };
        }
        
        const vec1 = VECTOR_CACHE.get(word1);
        const vec2 = VECTOR_CACHE.get(word2);
        
        if (!vec1 || !vec2) {
          return {
            statusCode: 404,
            headers,
            body: JSON.stringify({ 
              error: 'Vector not found',
              word1Found: !!vec1,
              word2Found: !!vec2,
              availableWords: Array.from(VECTOR_CACHE.keys())
            })
          };
        }
        
        const similarity = calculateCosineSimilarity(vec1, vec2);
        
        return {
          statusCode: 200,
          headers,
          body: JSON.stringify({
            word1,
            word2,
            similarity,
            similarityPercent: similarity * 100,
            method: 'real_vector_cosine',
            dimensions: vec1.length,
            timestamp: new Date().toISOString()
          })
        };
        
      case 'nearest':
        // ê¼¬ë§¨í‹€ì˜ most_similar í•¨ìˆ˜ êµ¬í˜„
        if (!word1) {
          return {
            statusCode: 400,
            headers,
            body: JSON.stringify({ error: 'Missing target word (word1)' })
          };
        }
        
        try {
          const closeness = dumpNearest(word1, VECTOR_CACHE);
          const nearestWords = Object.entries(closeness)
            .filter(([word, _]) => word !== word1) // ìê¸° ìì‹  ì œì™¸
            .sort(([,a], [,b]) => b[1] - a[1]) // ìœ ì‚¬ë„ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ
            .slice(0, 10); // ìƒìœ„ 10ê°œë§Œ
          
          return {
            statusCode: 200,
            headers,
            body: JSON.stringify({
              targetWord: word1,
              nearestWords: nearestWords.map(([word, [rank, sim]]) => ({
                word,
                rank,
                similarity: sim,
                similarityPercent: sim * 100
              })),
              method: 'numpy_style_nearest_search',
              timestamp: new Date().toISOString()
            })
          };
        } catch (error) {
          return {
            statusCode: 404,
            headers,
            body: JSON.stringify({ 
              error: 'Target word not found',
              targetWord: word1,
              message: error.message
            })
          };
        }
        
      case 'stats':
        // ê¼¬ë§¨í‹€ì˜ similarity stats ìƒì„±
        if (!word1) {
          return {
            statusCode: 400,
            headers,
            body: JSON.stringify({ error: 'Missing target word (word1)' })
          };
        }
        
        const stats = calculateSimilarityStats(word1);
        if (!stats) {
          return {
            statusCode: 404,
            headers,
            body: JSON.stringify({ 
              error: 'Could not generate stats',
              targetWord: word1
            })
          };
        }
        
        return {
          statusCode: 200,
          headers,
          body: JSON.stringify({
            targetWord: word1,
            stats: {
              top: stats.top,
              top10: stats.top10,
              rest: stats.rest,
              topPercent: stats.top * 100,
              top10Percent: stats.top10 * 100,
              restPercent: stats.rest * 100
            },
            totalWords: stats.totalWords,
            method: 'numpy_similarity_stats',
            timestamp: new Date().toISOString()
          })
        };
      
      case 'status':
        return {
          statusCode: 200,
          headers,
          body: JSON.stringify({
            initialized: isInitialized,
            cacheSize: VECTOR_CACHE.size,
            availableWords: Array.from(VECTOR_CACHE.keys()),
            timestamp: new Date().toISOString()
          })
        };
        
      default:
        return {
          statusCode: 400,
          headers,
          body: JSON.stringify({ 
            error: 'Invalid action', 
            validActions: ['similarity', 'nearest', 'stats', 'status']
          })
        };
    }
    
  } catch (error) {
    console.error('Vector cache error:', error);
    return {
      statusCode: 500,
      headers,
      body: JSON.stringify({ 
        error: 'Vector operation failed',
        message: error.message
      })
    };
  }
};
